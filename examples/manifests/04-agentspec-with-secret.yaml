apiVersion: apiary.io/v1
kind: AgentSpec
metadata:
  name: llm-agent
  namespace: default
  labels:
    app: llm
    tier: standard
spec:
  runtime:
    command:
      - python
      - agent.py
    workingDir: /app
    env:
      - name: OPENAI_API_KEY
        valueFrom:
          secretKeyRef:
            name: api-key-secret
            key: openai-api-key
      - name: MODEL
        value: "gpt-4"
  interface:
    type: stdin
  resources:
    requests:
      cpu: 500      # 500 millicores (0.5 CPU)
      memory: 512000000  # 512 MB
    limits:
      cpu: 2000     # 2000 millicores (2 CPU)
      memory: 2048000000  # 2 GB
  taskTier: standard
  scaling:
    minReplicas: 2
    maxReplicas: 20
    targetLatencyMs: 200
    scaleUpThreshold: 0.8
    scaleDownThreshold: 0.2
    cooldownSeconds: 120
  guardrails:
    responseTimeoutSeconds: 60
    rateLimitPerMinute: 30
    tokenBudgetPerRequest: 50000
    tokenBudgetPerSession: 500000
    tokenBudgetPerMinute: 100000
    outputSchema:
      type: object
      properties:
        response:
          type: string
        confidence:
          type: number
          minimum: 0
          maximum: 1
